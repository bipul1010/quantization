{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "import torch\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load MNIST Dataset\n",
    "\n",
    "#Make torch deterministic\n",
    "_ = torch.manual_seed(0)\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "#print(mnist_trainset[30][0].shape)\n",
    "train_loader = DataLoader(mnist_trainset,shuffle=True,batch_size=10)\n",
    "\n",
    "# for train_batch in train_loader:\n",
    "#     X,Y = train_batch[0],train_batch[1]\n",
    "#     print(X,Y)\n",
    "#     break\n",
    "#classes = [int(y) for x in train_loader for y in x[1]]\n",
    "output_classes = 10 ## len(set(classes))\n",
    "\n",
    "\n",
    "\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(mnist_testset,shuffle=True, batch_size=10)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural Network\n",
    "\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1:int=200,hidden_size_2=200) -> None:\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(28*28,hidden_size_1)\n",
    "        self.linear_2 = nn.Linear(hidden_size_1,hidden_size_2)\n",
    "        self.linear_3 = nn.Linear(hidden_size_2,output_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self,img):\n",
    "        ## (B,1,28,28) -> (B,28*28)\n",
    "        x = img.view(-1,28*28)\n",
    "        x = self.relu(self.linear_1(x)) ## (B,28*28) -> (B,200)\n",
    "        x = self.relu(self.linear_2(x)) ## (B,200) -> (B,200)\n",
    "        x = self.linear_3(x) ##(B,200) -> (B,10)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleNeuralNet().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##training\n",
    "\n",
    "def train(train_loader, model, epochs=5):\n",
    "    optimizer  = torch.optim.Adam(model.parameters(),lr=0.001,eps = 1e-9)\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(0,epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        batch_iterator = tqdm(train_loader,desc = f\"Processing Epoch: {epoch}\")\n",
    "        losses = []\n",
    "\n",
    "        for train_batch in batch_iterator:\n",
    "            X, Y = train_batch[0],train_batch[1] ##X -> (B,1,28,28) ; Y -> (B)\n",
    "            logits = model(X) ## (B,10)\n",
    "\n",
    "            loss = F.cross_entropy(logits,Y)\n",
    "            batch_iterator.set_postfix({\"loss\":loss.item()})\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            ##back propagate the loss and compute the gradient\n",
    "            loss.backward()\n",
    "\n",
    "            ## update the weight\n",
    "            optimizer.step()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        batch_iterator.write(f\"Epoch :{epoch} | Avg. Training Loss: {sum(losses) / len(losses)}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model_path = Path(\"model_path\")\n",
    "model_filename = str(model_path / \"simple_net.pt\")\n",
    "train(train_loader,model)\n",
    "torch.save(model.state_dict(),model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accu: 0.9706\n",
      "ModelSize: 798.959 KB\n"
     ]
    }
   ],
   "source": [
    "## test \n",
    "model_path = Path(\"model_path\")\n",
    "model_filename = str(model_path / \"simple_net.pt\")\n",
    "def test(test_loader, model):\n",
    "    total = 0\n",
    "    correct_match = 0\n",
    "    for test_batch in test_loader:\n",
    "        X,Y = test_batch[0],test_batch[1]\n",
    "\n",
    "        logits = model(X) ## (B,10)\n",
    "        value,predicted_labels = torch.max(logits,dim=1)\n",
    "        for y_predicted,y in zip(predicted_labels,Y):\n",
    "            if y_predicted == y:\n",
    "                correct_match += 1\n",
    "            total +=1\n",
    "\n",
    "    acc = correct_match / total\n",
    "    print(f\"Accu: {acc}\")\n",
    "    return acc\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(model_filename))\n",
    "\n",
    "test(test_loader,model)\n",
    "\n",
    "model_size = os.path.getsize(model_filename) / 1e3\n",
    "print(f\"ModelSize: {model_size} KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0476,  0.0670,  0.0185,  ...,  0.0698,  0.0516,  0.0499],\n",
      "        [-0.0219, -0.0171, -0.0125,  ..., -0.0224, -0.0081, -0.0320],\n",
      "        [-0.0385, -0.0035, -0.0516,  ..., -0.0387, -0.0172, -0.0103],\n",
      "        ...,\n",
      "        [ 0.0365,  0.0101,  0.0169,  ...,  0.0305,  0.0517,  0.0708],\n",
      "        [ 0.0675,  0.0146,  0.0127,  ...,  0.0154,  0.0383,  0.0618],\n",
      "        [ 0.0644,  0.0617,  0.0635,  ...,  0.0338,  0.0371,  0.0438]],\n",
      "       requires_grad=True) torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(model.linear_1.weight,model.linear_1.weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNeuralNet(\n",
      "  (linear_1): Linear(\n",
      "    in_features=784, out_features=200, bias=True\n",
      "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (linear_2): Linear(\n",
      "    in_features=200, out_features=200, bias=True\n",
      "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (linear_3): Linear(\n",
      "    in_features=200, out_features=10, bias=True\n",
      "    (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "##Configure the quantization settings\n",
    "#print(torch.backends.quantized.supported_engines)\n",
    "torch.backends.quantized.engine = \"qnnpack\" ## this is important to set. \n",
    "quantization_config = torch.quantization.get_default_qconfig('qnnpack')\n",
    "\n",
    "\n",
    "##Prepare the model for quantization\n",
    "model.qconfig = quantization_config\n",
    "quantized_model = torch.quantization.prepare(model)\n",
    "print(quantized_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accu: 0.9706\n",
      "SimpleNeuralNet(\n",
      "  (linear_1): Linear(\n",
      "    in_features=784, out_features=200, bias=True\n",
      "    (activation_post_process): HistogramObserver(min_val=-88.74122619628906, max_val=59.636592864990234)\n",
      "  )\n",
      "  (linear_2): Linear(\n",
      "    in_features=200, out_features=200, bias=True\n",
      "    (activation_post_process): HistogramObserver(min_val=-75.33014678955078, max_val=63.807403564453125)\n",
      "  )\n",
      "  (linear_3): Linear(\n",
      "    in_features=200, out_features=10, bias=True\n",
      "    (activation_post_process): HistogramObserver(min_val=-153.69056701660156, max_val=44.299156188964844)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "##Calibrate the model\n",
    "test(test_loader,quantized_model)\n",
    "print(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleNeuralNet(\n  (linear_1): QuantizedLinear(in_features=784, out_features=200, scale=0.45117953419685364, zero_point=159, qscheme=torch.per_tensor_affine)\n  (linear_2): QuantizedLinear(in_features=200, out_features=200, scale=0.4129579961299896, zero_point=150, qscheme=torch.per_tensor_affine)\n  (linear_3): QuantizedLinear(in_features=200, out_features=10, scale=0.7180463671684265, zero_point=198, qscheme=torch.per_tensor_affine)\n  (relu): ReLU()\n)"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert the model into a quantized form\n",
    "torch.quantization.convert(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Normal Model Weight: {model.linear_1.weight} | Dtype: {model.linear_1.weight.dtype}\")\n",
    "print(f\"Quantized Model Weight: {quantized_model.linear_1.weight} | Dtype: {quantized_model.linear_1.weight.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantizedModelSize: 827.175 KB\n",
      "Accu: 0.9706\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9706"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model_filename = str(model_path / \"quantized_net.pt\")\n",
    "torch.save(quantized_model.state_dict(),quantized_model_filename)\n",
    "\n",
    "quantized_model_size = os.path.getsize(quantized_model_filename) / 1e3\n",
    "print(f\"QuantizedModelSize: {quantized_model_size} KB\")\n",
    "\n",
    "\n",
    "test(test_loader,quantized_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('env_tf': conda)",
   "name": "python3912jvsc74a57bd091fb269e76fb65aec614b254347815de645e41e2277fead135e480146975292d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "91fb269e76fb65aec614b254347815de645e41e2277fead135e480146975292d"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}